/**
 * ğŸ”± AutoSite Learner
 * URLã‚’å­¦ç¿’â†’ã‚µã‚¤ãƒˆå°‚ç”¨Indexç”Ÿæˆ
 * 
 * æ©Ÿèƒ½:
 * - ã‚µã‚¤ãƒˆã‚’ã‚¯ãƒ­ãƒ¼ãƒ«
 * - ãƒšãƒ¼ã‚¸å†…å®¹ã‚’æŠ½å‡º
 * - ã‚µã‚¤ãƒˆå°‚ç”¨Semantic Indexã«è¿½åŠ 
 */

import { addDocumentToIndex } from "./semantic/index";
import type { Document } from "./semantic/index";

/**
 * ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼çµæœï¼ˆãƒšãƒ¼ã‚¸æƒ…å ±ï¼‰
 */
export interface CrawledPage {
  url: string;
  path: string;
  title: string;
  content: string;
  metadata?: Record<string, unknown>;
}

/**
 * ã‚µã‚¤ãƒˆã‚’è‡ªå‹•å­¦ç¿’
 * 
 * @param url - ã‚¯ãƒ­ãƒ¼ãƒ«é–‹å§‹URL
 * @param siteId - ã‚µã‚¤ãƒˆIDï¼ˆä¾‹: "example-com"ï¼‰
 * @param options - ã‚ªãƒ—ã‚·ãƒ§ãƒ³
 * @returns å­¦ç¿’çµæœ
 */
export async function autoLearnSite(
  url: string,
  siteId: string,
  options?: {
    maxPages?: number; // æœ€å¤§ãƒšãƒ¼ã‚¸æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50ï¼‰
    depth?: number; // ã‚¯ãƒ­ãƒ¼ãƒ«æ·±åº¦ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2ï¼‰
  }
): Promise<{ pages: number; siteId: string }> {
  const maxPages = options?.maxPages || 50;
  const depth = options?.depth || 2;

  try {
    // ã‚µã‚¤ãƒˆã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’ä½¿ç”¨ï¼ˆæ—¢å­˜å®Ÿè£…ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ï¼‰
    let crawledPages: CrawledPage[] = [];

    try {
      // æ—¢å­˜ã®ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’ä½¿ç”¨
      const { crawlSite } = await import("../siteCrawler/crawlerEngine");
      const result = await crawlSite(url, { maxPages, maxDepth: depth });
      
      // PageDataã‚’CrawledPageã«å¤‰æ›
      crawledPages = result.pages.map((page) => ({
        url: page.url,
        path: new URL(page.url).pathname || "/",
        title: page.title || "Untitled",
        content: page.textContent || "",
        metadata: page.metadata,
      }));
    } catch (error) {
      // ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ç°¡æ˜“å®Ÿè£…
      console.warn("[AutoSite Learner] Crawler not found, using simple fetch:", error);
      crawledPages = await simpleCrawl(url, maxPages);
    }

    // å„ãƒšãƒ¼ã‚¸ã‚’Semantic Indexã«è¿½åŠ 
    let addedCount = 0;
    for (const page of crawledPages) {
      const document: Document = {
        id: `${siteId}:${page.path}`,
        text: `${page.title}\n\n${page.content}`,
        metadata: {
          siteId,
          url: page.url,
          path: page.path,
          title: page.title,
        },
      };

      const result = await addDocumentToIndex(siteId, document);
      if (result.success) {
        addedCount++;
      } else {
        console.error(`[AutoSite Learner] Failed to add document ${document.id}:`, result.error);
      }
    }

    console.log(`[AutoSite Learner] Learned ${addedCount} pages from ${url} (siteId: ${siteId})`);

    return {
      pages: addedCount,
      siteId,
    };
  } catch (error) {
    console.error("[AutoSite Learner] Error:", error);
    throw error;
  }
}

/**
 * ç°¡æ˜“ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ï¼ˆæ—¢å­˜ã‚¯ãƒ­ãƒ¼ãƒ©ãƒ¼ãŒãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
 */
async function simpleCrawl(url: string, maxPages: number): Promise<CrawledPage[]> {
  const pages: CrawledPage[] = [];
  const visited = new Set<string>();

  async function crawlPage(currentUrl: string): Promise<void> {
    if (pages.length >= maxPages || visited.has(currentUrl)) {
      return;
    }

    visited.add(currentUrl);

    try {
      // ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰ã§fetchã‚’ä½¿ç”¨ï¼ˆNode.js 18+ï¼‰
      const response = await fetch(currentUrl, {
        headers: {
          "User-Agent": "TENMON-ARK AutoSite Learner/1.0",
        },
      });

      if (!response.ok) {
        return;
      }

      const html = await response.text();

      // ç°¡æ˜“çš„ãªHTMLãƒ‘ãƒ¼ã‚¹ï¼ˆtitleã¨bodyãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼‰
      const titleMatch = html.match(/<title[^>]*>([^<]+)<\/title>/i);
      const title = titleMatch ? titleMatch[1].trim() : "Untitled";

      // bodyã‚¿ã‚°å†…ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
      const bodyMatch = html.match(/<body[^>]*>([\s\S]*?)<\/body>/i);
      let content = "";
      if (bodyMatch) {
        // HTMLã‚¿ã‚°ã‚’é™¤å»ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        content = bodyMatch[1]
          .replace(/<script[^>]*>[\s\S]*?<\/script>/gi, "")
          .replace(/<style[^>]*>[\s\S]*?<\/style>/gi, "")
          .replace(/<[^>]+>/g, " ")
          .replace(/\s+/g, " ")
          .trim()
          .slice(0, 5000); // æœ€å¤§5000æ–‡å­—
      }

      if (content.length > 100) {
        // URLã‹ã‚‰ãƒ‘ã‚¹ã‚’æŠ½å‡º
        const urlObj = new URL(currentUrl);
        const path = urlObj.pathname || "/";

        pages.push({
          url: currentUrl,
          path,
          title,
          content,
        });
      }
    } catch (error) {
      console.error(`[AutoSite Learner] Failed to crawl ${currentUrl}:`, error);
    }
  }

  // æœ€åˆã®ãƒšãƒ¼ã‚¸ã‚’ã‚¯ãƒ­ãƒ¼ãƒ«
  await crawlPage(url);

  return pages;
}

